# Voice Chat Test Dataflow - Using Fake Nodes for Testing
#
# This dataflow uses fake/mock nodes instead of real AI APIs
# to test the data flow and MoFA dynamic node integration
# without requiring actual API keys or external services.
#
# Fake nodes generate predefined responses to simulate conversation

nodes:
  # ============ Fake LLM Participants ============

  - id: myself
    path: fake_nodes/fake_llm.py
    inputs:
      text: bridge-to-myself/text
      control: conference-controller/llm_control
    outputs:
      - text
      - status
      - log
    env:
      PARTICIPANT_ID: myself

  - id: techer
    path: fake_nodes/fake_llm.py
    inputs:
      text: bridge-to-techer/text
      control: conference-controller/llm_control
    outputs:
      - text
      - status
      - log
    env:
      PARTICIPANT_ID: techer

  # ============ Fake Text Segmenter ============

  - id: multi-text-segmenter
    path: fake_nodes/fake_text_segmenter.py
    inputs:
      myself:
        source: myself/text
        queue_size: 1000
      techer:
        source: techer/text
        queue_size: 1000
      audio_complete:
        source: mofa-audio-player/audio_complete
        queue_size: 100
      audio_buffer_control:
        source: mofa-audio-player/buffer_status
        queue_size: 10
      control: conference-controller/llm_control
      reset: conference-controller/control_judge
    outputs:
      - text_segment_myself
      - text_segment_techer
      - status
      - metrics
      - log

  # ============ Fake TTS Nodes ============

  - id: primespeech-myself
    path: fake_nodes/fake_tts.py
    inputs:
      text: multi-text-segmenter/text_segment_myself
    outputs:
      - audio
      - status
      - segment_complete
      - log
    env:
      VOICE_NAME: Zhao Daniu
      PARTICIPANT_ID: myself

  - id: primespeech-techer
    path: fake_nodes/fake_tts.py
    inputs:
      text: multi-text-segmenter/text_segment_techer
    outputs:
      - audio
      - status
      - segment_complete
      - log
    env:
      VOICE_NAME: Chen Yifan
      PARTICIPANT_ID: techer

  # ============ Fake Conference Bridges ============

  - id: bridge-to-myself
    path: fake_nodes/fake_bridge.py
    inputs:
      techer:
        source: techer/text
        queue_size: 1000
      control:
        source: conference-controller/control_llm1
        queue_size: 10
    outputs:
      - text
      - status
      - log
    env:
      BRIDGE_TARGET: myself

  - id: bridge-to-techer
    path: fake_nodes/fake_bridge.py
    inputs:
      myself:
        source: myself/text
        queue_size: 1000
      control:
        source: conference-controller/control_llm2
        queue_size: 10
    outputs:
      - text
      - status
      - log
    env:
      BRIDGE_TARGET: techer

  # ============ Fake Conference Controller ============

  - id: conference-controller
    path: fake_nodes/fake_conference_controller.py
    inputs:
      myself:
        source: myself/text
        queue_size: 1000
      techer:
        source: techer/text
        queue_size: 1000
      control: mofa-prompt-input/control
      session_start: mofa-audio-player/session_start
      buffer_status: mofa-audio-player/buffer_status
    outputs:
      - control_judge
      - control_llm2
      - control_llm1
      - llm_control
      - judge_prompt
      - status
      - log

  # ============ MoFA Dynamic Nodes (UI Widgets) ============

  - id: mofa-audio-player
    path: dynamic
    inputs:
      audio_myself:
        source: primespeech-myself/audio
        queue_size: 1000
      audio_techer:
        source: primespeech-techer/audio
        queue_size: 1000
      control:
        source: conference-controller/llm_control
        queue_size: 10
    outputs:
      - buffer_status
      - status
      - session_start
      - audio_complete
      - log

  - id: mofa-prompt-input
    path: dynamic
    env:
      DORA_STUDY_MODE: true
      LOG_LEVEL: DEBUG
    inputs:
      llm1_text:
        source: myself/text
        queue_size: 1000
      llm2_text:
        source: techer/text
        queue_size: 1000
    outputs:
      - control

  - id: mofa-system-log
    path: dynamic
    inputs:
      llm1_log:
        source: myself/log
        queue_size: 1000
      llm1_status: myself/status
      llm1_text:
        source: myself/text
        queue_size: 1000
      llm2_log:
        source: techer/log
        queue_size: 1000
      llm2_status: techer/status
      llm2_text:
        source: techer/text
        queue_size: 1000
      bridge1_log:
        source: bridge-to-myself/log
        queue_size: 1000
      bridge1_status: bridge-to-myself/status
      bridge1_text:
        source: bridge-to-myself/text
        queue_size: 1000
      bridge2_log:
        source: bridge-to-techer/log
        queue_size: 1000
      bridge2_status: bridge-to-techer/status
      bridge2_text:
        source: bridge-to-techer/text
        queue_size: 1000
      controller_status: conference-controller/status
      controller_log:
        source: conference-controller/log
        queue_size: 1000
      control_judge: conference-controller/control_judge
      control_llm2: conference-controller/control_llm2
      control_llm1: conference-controller/control_llm1
      segmenter_log:
        source: multi-text-segmenter/log
        queue_size: 1000
      segmenter_status: multi-text-segmenter/status
      tts1_log:
        source: primespeech-myself/log
        queue_size: 1000
      tts1_status: primespeech-myself/status
      tts2_log:
        source: primespeech-techer/log
        queue_size: 1000
      tts2_status: primespeech-techer/status
      audio_status: mofa-audio-player/status
      audio_player_log:
        source: mofa-audio-player/log
        queue_size: 1000
