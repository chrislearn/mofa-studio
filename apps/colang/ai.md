# 英语学习伴侣

重构 colang 文件夹下的的代码:

== 核心修改:

创建一个sqlite 数据库, 用 sqlx 操作它, 它包含一个数据库 issue_words, 数据库里面至少包含一下字段:

id 递增主键
word 字符串类型, 对应用户可能有问题的单词.
issue 字符串类型, 说明用户的问题是什么, 类型包含: 单词用法错误, 发音错误, 不会使用 等.
last_picked_at 最后一次被选取的时间, 避免一个单词重复被选中.
create_at 创建时间戳, 后面根据这个时间戳, 决定合适抽取给用户复习.

你可以根据后续需求添加更多的数据库表, 也可以更改上述字段, 添加字段.


主要修改 dataflow 文件夹下的 dora 数据流.

- 不再使用本地模型, 你需要改成使用 豆包 的火山引擎提供的 ai 语音识别和合成相关功能的 api.
- 把当前的对话流程改为:
<第一步>: 有一个 dora node 会从数据库中选出几个用户需要复习掌握的单词, 大概 20-30 个, 注意每个单词的选取频率为一天最多2-5次.
然后, 根据这些单词, 以及聊天的上下文, 让AI 的 API生成一个话题的文本内容.　如果数据库中单词不够或者没有，就直接让AI API 根据聊天的上下文生成话题的文本.
可以告诉　AI API 需要生成地道的英语内容, 结合时政, 工作场景等.
把文本内容转为地道美语
主动调用声音输出设备, 与用户对话, 开始聊天. 实时聊天功能来自于豆包 的火山引擎. 需要你集成他们.

听取用户说话的内容, 把内容转换为文字.

继续生成后续对话内容, 如此一直与用户对话.

注意给 api 的系统提示类似这样:
你是一个专业英语教师, 你的任务是教会用户如何说好地道英语.所以你尽量讲的是英语, 只有在用户表示他无法理解你说的内容的情况下才会切换到中文解释.

把聊天的内容转换为文字, 打印到 Chat History 窗口中. 现在的流程中已经有类似的功能, 最小化修改, 满足这个要求.

收集用户聊天的语音, 发现发音的问题, 收集整理, 放入 sqlite 数据库.
收集用户聊天的语音, 发现用户表达不流畅的点, 根据整体意思, 把对应部分可能的生字词, 放入 sqlite 数据库.
收集用户聊天的语音转换成的文本中的单词用法问题, 或者可以改进的, 更合适的单词, 或者用户表达卡壳的地方都单词, 放入 sqlite 数据库.
数据库中需要同时放入出现问题的时间点.

所有的对话内容需要保持至 sqlite 数据库, 并且对聊天的用户表达有问题的地方给予注释, 注释也放在数据库中.

根据发现的用户问题, 比如句型问题, 单词不熟等, 根据之前放入数据库中的时间点, 制定不同的复习频率.

依据此频率回到流程的<第一步>, 重复生成对话.